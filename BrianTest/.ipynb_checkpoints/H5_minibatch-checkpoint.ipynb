{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import glob\n",
    "\n",
    "import torch \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "import numpy as np\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "from file_io import read, write\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset(Dataset):\n",
    "    def __init__(self, \n",
    "                 root,\n",
    "                 input_tfm_function,\n",
    "#                  gt_tfm_function,\n",
    "                 input_folder_1 = \"image_2\", \n",
    "                 input_folder_2 = \"image_2\", \n",
    "                 gt_folder = \"flow_occ\",\n",
    "                 input_search_param_1=\"*_10.png\", \n",
    "                 input_search_param_2 = \"*_11.png\", \n",
    "                 gt_search_param = \"*_10.png\"):\n",
    "        \n",
    "        self.root = Path(root)\n",
    "        self.input1_dir = self.root/input_folder_1\n",
    "        self.input2_dir = self.root/input_folder_2\n",
    "        self.gt_dir = self.root/gt_folder\n",
    "        \n",
    "        self.input_1_names = sorted([os.path.basename(x) for x in self.input1_dir.glob(input_search_param_1)])\n",
    "        self.input_2_names = sorted([os.path.basename(x) for x in self.input2_dir.glob(input_search_param_2)])\n",
    "        self.gt_names = sorted([os.path.basename(x) for x in self.gt_dir.glob(gt_search_param)])\n",
    "        self.input_tfm_function = input_tfm_function\n",
    "#         self.gt_tfm_function = gt_tfm_function\n",
    "        \n",
    "#         for a,b,c in zip(self.input_1_names,self.input_2_names,self.gt_names):\n",
    "#             print(a,b,c)\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.input_1_names)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "#         print(idx)\n",
    "#         print(self.input_1_names[idx],self.input_2_names[idx],self.gt_names[idx])\n",
    "        input1 = read(str(self.input1_dir/self.input_1_names[idx]))\n",
    "        input2 = read(str(self.input2_dir/self.input_2_names[idx]))\n",
    "        gt = read(str(self.gt_dir/self.gt_names[idx]))\n",
    "        \n",
    "#         input1 = self.input_tfm_function(input1)\n",
    "#         input2 = self.input_tfm_function(input2)\n",
    "#         gt = self.gt_tfm_function(gt)\n",
    "        if gt is not None:\n",
    "            input1,input2,gt = self.input_tfm_function(input1,input2,gt)\n",
    "        else:\n",
    "            print(\"GT missing\")\n",
    "        return input1, input2, gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tn_flo_to_PIL_flow_image(flo):\n",
    "    max_abs = max(flo.min(), flo.max(), key=abs)\n",
    "    mean = (0, 0)\n",
    "    std = (max_abs, max_abs)\n",
    "    nor1_1 = transforms.Normalize(mean=mean, std=std)\n",
    "    mean = (-1, -1)\n",
    "    std = (2, 2)\n",
    "    nor0_1 = transforms.Normalize(mean=mean, std=std)\n",
    "    \n",
    "    flo = nor1_1(flo)\n",
    "    img = nor0_1(flo)\n",
    "    padding = torch.zeros(1, img.shape[1], img.shape[2])\n",
    "    img = torch.cat((img, padding), 0)\n",
    "    \n",
    "    return TF.to_pil_image(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_Kitti_flow_image_to_flo(flo_img):\n",
    "    mean = (0, 0, 0)\n",
    "    std = (255, 255, 255)\n",
    "    nor0_1 = transforms.Normalize(mean=mean, std=std)\n",
    "    mean = (0.5, 0.5, 0.5)\n",
    "    std = (0.5, 0.5, 0.5)\n",
    "    nor = transforms.Normalize(mean=mean, std=std)\n",
    "    flo_img = torch.from_numpy(flo_img)\n",
    "    flo_img = flo_img.permute(2,0,1)\n",
    "    flo_img = nor0_1(flo_img)\n",
    "    flow = nor(flo_img)\n",
    "    flow = flow.permute(1,2,0)\n",
    "    return flow[:,:,0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pil_norm_flow_image_to_flo(flo_img):\n",
    "    flo_img = TF.to_tensor(flo_img)\n",
    "    mean = (0.5, 0.5, 0.5)\n",
    "    std = (0.5, 0.5, 0.5)\n",
    "    nor = transforms.Normalize(mean=mean, std=std)\n",
    "    flow = nor(flo_img)\n",
    "    flow = flow.permute(1,2,0)\n",
    "    return flow[:,:,0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pil_flow_image_to_flo(flo_img):\n",
    "    flo_img = TF.to_tensor(flo_img)\n",
    "    mean = (0, 0, 0)\n",
    "    std = (255, 255, 255)\n",
    "    nor0_1 = transforms.Normalize(mean=mean, std=std)\n",
    "    mean = (0.5, 0.5, 0.5)\n",
    "    std = (0.5, 0.5, 0.5)\n",
    "    nor = transforms.Normalize(mean=mean, std=std)\n",
    "    flo_img = nor0_1(flo_img)\n",
    "    flow = nor(flo_img)\n",
    "    flow = flow.permute(1,2,0)\n",
    "    return flow[:,:,0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlowDatasetTransform():\n",
    "    def __init__(self, norm, size=(375, 1242), crop=(320, 896), flip=.5):\n",
    "        self.norm = norm\n",
    "        self.size = size\n",
    "        self.crop = crop\n",
    "        self.flip = .5\n",
    "\n",
    "        mean = np.array(self.norm.mean)\n",
    "        std = np.array(self.norm.std)\n",
    "\n",
    "        self.inv_norm = transforms.Normalize(mean=-mean*std, std=1/std)\n",
    "\n",
    "    def __call__(self, im_1, im_2, target):\n",
    "#         to_PIL = transforms.ToPILImage()\n",
    "        resize = transforms.Resize(size=self.size)\n",
    "     \n",
    "        \n",
    "        norm_Pil = False\n",
    "        \n",
    "        if type(target) is np.ndarray:\n",
    "            if(target.shape[2] is 3): #png\n",
    "                c = TF.to_pil_image(np.uint8(target))\n",
    "            else: #flo\n",
    "                v = torch.from_numpy(target)\n",
    "                v = v.permute(2,0,1)\n",
    "                c = tn_flo_to_PIL_flow_image(v)\n",
    "                norm_Pil = True\n",
    "        \n",
    "        if type(c) is not PIL.Image.Image:\n",
    "            print(\"error\")\n",
    "            raise Exception('target_type not PIL');\n",
    "            \n",
    "            \n",
    "        \n",
    "#         print(im_1)\n",
    "        a = TF.to_pil_image(np.uint8(im_1))\n",
    "        b = TF.to_pil_image(np.uint8(im_2))\n",
    "        \n",
    "        \n",
    "\n",
    "        im_1 = resize(a)\n",
    "        im_2 = resize(b)\n",
    "        target = resize(c)\n",
    "        \n",
    "        \n",
    "#         if type(target) is not PIL.PngImagePlugin.PngImageFile:\n",
    "#             target = TF.to_tensor(target)\n",
    "#             if target.shape[0] == 2:\n",
    "#                 padding = torch.zeros(1, target.shape[1], target.shape[2])\n",
    "#                 target = torch.cat((target, padding), 0)\n",
    "#             target = to_PIL(target)\n",
    "\n",
    "        i, j, h, w = transforms.RandomCrop.get_params(im_1, output_size=self.crop)\n",
    "\n",
    "        im_1 = TF.crop(im_1, i, j, h, w)\n",
    "        im_2 = TF.crop(im_2, i, j, h, w)\n",
    "        target = TF.crop(target, i, j, h, w)\n",
    "        \n",
    "\n",
    "        if random.random() > self.flip:\n",
    "            im_1 = TF.hflip(im_1)\n",
    "            im_2 = TF.hflip(im_2)\n",
    "            target = TF.hflip(target)\n",
    "\n",
    "        im_1 = TF.to_tensor(im_1)\n",
    "        im_2 = TF.to_tensor(im_2)\n",
    "#         target = TF.to_tensor(target)\n",
    "#         if(norm_Pil is True):\n",
    "        target = pil_norm_flow_image_to_flo(target) #onlu if Pil was not there\n",
    "#         else:\n",
    "#             target = pil_flow_image_to_flo(target)\n",
    "            \n",
    "            \n",
    "            \n",
    "#        if target_type is PIL.Image.Image:\n",
    "#         print(target.shape)\n",
    "\n",
    "        return im_1, im_2, target\n",
    "\n",
    "    def denorm(self, im):\n",
    "        return self.inv_norm(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # set the transform\n",
    "# transform = transforms.Compose([\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.ToPILImage(),\n",
    "#         transforms.Resize((512,512), interpolation=2),\n",
    "#         transforms.ToTensor()\n",
    "#         ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = (.5, .5, .5)\n",
    "std = (.5, .5, .5)\n",
    "norm = transforms.Normalize(mean=mean, std=std)\n",
    "\n",
    "transform = FlowDatasetTransform(norm,size=(384, 512),crop=(384,448))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_loader_kitti = dataset(\"../Data/KittiDataset/training\",\n",
    "#                        transform,\n",
    "#                        input_folder_1 = \"image_2\", \n",
    "#                        input_folder_2 = \"image_2\", \n",
    "#                        gt_folder = \"flow_occ\",\n",
    "#                        input_search_param_1=\"*_10.png\", \n",
    "#                        input_search_param_2 = \"*_11.png\", \n",
    "#                        gt_search_param = \"*_10.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_FlyingChairs = dataset(\"../Data/FlyingChairs_release\",\n",
    "                       transform,\n",
    "                       input_folder_1 = \"data\", \n",
    "                       input_folder_2 = \"data\", \n",
    "                       gt_folder = \"data\",\n",
    "                       input_search_param_1=\"*_img_1.ppm\", \n",
    "                       input_search_param_2 = \"*_img_1.ppm\", \n",
    "                       gt_search_param = \"*_flow.flo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_kitti = torch.utils.data.DataLoader(train_loader_kitti,4,shuffle=True,num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "num_samples should be a positive integer value, but got num_samples=0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-2b0a3f79f853>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataset_flyingChairs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader_FlyingChairs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context)\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# map-style\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m                     \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                     \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequentialSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/sampler.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data_source, replacement, num_samples)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_samples\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             raise ValueError(\"num_samples should be a positive integer \"\n\u001b[0;32m---> 94\u001b[0;31m                              \"value, but got num_samples={}\".format(self.num_samples))\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: num_samples should be a positive integer value, but got num_samples=0"
     ]
    }
   ],
   "source": [
    "dataset_flyingChairs = torch.utils.data.DataLoader(train_loader_FlyingChairs,8,shuffle=True,num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_H5(dataset, path):\n",
    "    index = 0\n",
    "    for inputs1,inputs2,target in dataset:\n",
    "#         print(index)\n",
    "        with h5py.File(path + str(index), 'w') as f:\n",
    "            in1 = f.create_dataset('img1', dtype=np.float32,data=inputs1,compression=\"gzip\", compression_opts=9)\n",
    "            in2 = f.create_dataset('img2', dtype=np.float32,data=inputs2,compression=\"gzip\", compression_opts=9)    \n",
    "#             flo = pil_norm_flow_image_to_flo(target)\n",
    "            targ = f.create_dataset('target', dtype=np.float32,data=target,compression=\"gzip\", compression_opts=9)\n",
    "            index+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_H5(index, path):\n",
    "    with h5py.File(path + str(index), 'r') as f:\n",
    "        img1 = f[\"img1\"][()]\n",
    "        img2 = f[\"img2\"][()]\n",
    "        trg = f[\"target\"][()]\n",
    "        img1_file = torch.from_numpy(img1)\n",
    "        img2_file = torch.from_numpy(img2)\n",
    "        target_file = torch.from_numpy(trg)\n",
    "        return img1_file,img2_file,target_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_batch(im1,im2,target):\n",
    "    for image_1, image_2, target_image in zip(im1,im2,target):\n",
    "        im1_print = image_1.numpy().transpose((1,2,0))\n",
    "        im2_print = image_2.numpy().transpose((1,2,0))\n",
    "        \n",
    "#         print(target_image.shape)\n",
    "\n",
    "#         z = np.zeros((target_image.shape[1],target_image.shape[2]))\n",
    "#         target_print = np.stack((target_image[0],target_image[1], z), axis=0)\n",
    "#         target_print = target_print.transpose((1,2,0))\n",
    "#         print(target_print.shape)\n",
    "#         print(target_image.shape)\n",
    "        print(target_image.shape)\n",
    "#         padding = torch.zeros(target_image.shape[0], target_image.shape[1],1)\n",
    "# #         print(padding.shape)\n",
    "#         target_image = torch.cat((target_image, padding), 2)\n",
    "    \n",
    "        print(torch.max(target_image))\n",
    "        print(torch.min(target_image))\n",
    "        print(target_image.shape)\n",
    "        \n",
    "        target_image = target_image.permute(2,0,1)\n",
    "        target_print=tn_flo_to_PIL_flow_image(target_image)\n",
    "\n",
    "        fig, ax = plt.subplots(1, 3, figsize=(15, 20))\n",
    "        for a in ax:\n",
    "          a.set_axis_off()\n",
    "\n",
    "        ax[0].imshow(im1_print)\n",
    "        ax[1].imshow(im2_print)\n",
    "        ax[2].imshow(target_print)\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write_H5(dataset_kitti, path = '../Data/H5/512by512Kitti/mini_batch_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "write_H5(dataset_flyingChairs, path = '../Data/H5/FlyingChairs2/mini_batch_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im1,im2,target = read_H5(56\n",
    "                         ,path = '../Data/H5/FlyingChairs2/mini_batch_')\n",
    "print_batch(im1,im2,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read(\"../Data/ChairsSDHom_extended/train/0004142-flow_01.flo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read(\"../Data/ChairsSDHom_extended/train/0007785-img_1.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Path(\"../Data/ChairsSDHom_extended/train/0004142-flow_01.flo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = os.path.basename(root)\n",
    "dir = Path(os.path.dirname(root))\n",
    "s = s.replace('-flow_01.flo', '')\n",
    "im = s + '-img_0.png'\n",
    "ir = s + '-img_1.png'\n",
    "print(dir/im)\n",
    "print(dir/ir)\n",
    "\n",
    "\n",
    "print(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = Image.open('../Data/ChairsSDHom_extended/train/0010306-img_1.png')\n",
    "print(u)\n",
    "type(u)\n",
    "# resize = transforms.Resize((100,100))\n",
    "# resize(u)\n",
    "# u.show()\n",
    "# print(u.width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv2.imread('../Data/ChairsSDHom_extended/train/0004050-img_1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
