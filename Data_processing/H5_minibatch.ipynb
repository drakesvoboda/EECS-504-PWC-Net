{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import glob\n",
    "\n",
    "import torch \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "import numpy as np\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "from file_io import read, write\n",
    "import h5py\n",
    "from util import *\n",
    "import flow_vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlowDataset(Dataset):\n",
    "    def __init__(self, root, tfm_function, image_folder=\"data\", flow_folder=\"data\"):\n",
    "        super(FlowDataset, self).__init__()\n",
    "        self.root = Path(root)\n",
    "        self.image_dir = self.root/image_folder\n",
    "        self.flow_dir = self.root/flow_folder\n",
    "        self.im_1 = sorted([os.path.basename(x) for x in self.image_dir.glob(\"*_img1.ppm\")])\n",
    "        self.im_2 = sorted([os.path.basename(x) for x in self.image_dir.glob(\"*_img2.ppm\")])\n",
    "        self.flow = sorted([os.path.basename(x) for x in self.flow_dir.glob(\"*_flow.flo\")])\n",
    "        self.tfm_function = tfm_function\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.im_1)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        im_1 = Image.open(self.image_dir/self.im_1[idx]).convert('RGB')\n",
    "        im_2 = Image.open(self.image_dir/self.im_2[idx]).convert('RGB')\n",
    "        target = read(str(self.flow_dir/self.flow[idx]))\n",
    "        \n",
    "        im_1, im_2, target = self.tfm_function(im_1, im_2, target)\n",
    "\n",
    "        return im_1, im_2, target # The third channel of target is all zeros. I think the first two channels are the x and y components of the vector for that pixel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset2(Dataset):\n",
    "    def __init__(self, \n",
    "                 root,\n",
    "                 input_tfm_function,\n",
    "#                  gt_tfm_function,\n",
    "                 input_folder_1 = \"image_2\", \n",
    "                 input_folder_2 = \"image_2\", \n",
    "                 gt_folder = \"flow_occ\",\n",
    "                 input_search_param_1=\"*_10.png\", \n",
    "                 input_search_param_2 = \"*_11.png\", \n",
    "                 gt_search_param = \"*_10.png\"):\n",
    "        \n",
    "        self.root = Path(root)\n",
    "        self.input1_dir = self.root/input_folder_1\n",
    "        self.input2_dir = self.root/input_folder_2\n",
    "        self.gt_dir = self.root/gt_folder\n",
    "        \n",
    "        self.input_1_names = sorted([os.path.basename(x) for x in self.input1_dir.glob(input_search_param_1)])\n",
    "        self.input_2_names = sorted([os.path.basename(x) for x in self.input2_dir.glob(input_search_param_2)])\n",
    "        self.gt_names = sorted([os.path.basename(x) for x in self.gt_dir.glob(gt_search_param)])\n",
    "        self.input_tfm_function = input_tfm_function\n",
    "#         self.gt_tfm_function = gt_tfm_function\n",
    "        \n",
    "#         for a,b,c in zip(self.input_1_names,self.input_2_names,self.gt_names):\n",
    "#             print(a,b,c)\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.input_1_names)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "#         print(idx)\n",
    "#         print(self.input_1_names[idx],self.input_2_names[idx],self.gt_names[idx])\n",
    "        input1 = read(str(self.input1_dir/self.input_1_names[idx]))\n",
    "        input2 = read(str(self.input2_dir/self.input_2_names[idx]))\n",
    "        gt = read(str(self.gt_dir/self.gt_names[idx]))\n",
    "        \n",
    "#         input1 = self.input_tfm_function(input1)\n",
    "#         input2 = self.input_tfm_function(input2)\n",
    "#         gt = self.gt_tfm_function(gt)\n",
    "        if gt is not None:\n",
    "            input1,input2,gt = self.input_tfm_function(input1,input2,gt)\n",
    "        else:\n",
    "            print(\"GT missing\")\n",
    "        return input1, input2, gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def tn_flo_to_PIL_flow_image(flo):\n",
    "#     max_abs = max(flo.min(), flo.max(), key=abs)\n",
    "#     mean = (0, 0)\n",
    "#     std = (max_abs, max_abs)\n",
    "#     nor1_1 = transforms.Normalize(mean=mean, std=std)\n",
    "#     mean = (-1, -1)\n",
    "#     std = (2, 2)\n",
    "#     nor0_1 = transforms.Normalize(mean=mean, std=std)\n",
    "    \n",
    "#     flo = nor1_1(flo)\n",
    "#     img = nor0_1(flo)\n",
    "#     padding = torch.zeros(1, img.shape[1], img.shape[2])\n",
    "#     img = torch.cat((img, padding), 0)\n",
    "    \n",
    "#     return TF.to_pil_image(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def np_Kitti_flow_image_to_flo(flo_img):\n",
    "#     mean = (0, 0, 0)\n",
    "#     std = (255, 255, 255)\n",
    "#     nor0_1 = transforms.Normalize(mean=mean, std=std)\n",
    "#     mean = (0.5, 0.5, 0.5)\n",
    "#     std = (0.5, 0.5, 0.5)\n",
    "#     nor = transforms.Normalize(mean=mean, std=std)\n",
    "#     flo_img = torch.from_numpy(flo_img)\n",
    "#     flo_img = flo_img.permute(2,0,1)\n",
    "#     flo_img = nor0_1(flo_img)\n",
    "#     flow = nor(flo_img)\n",
    "#     flow = flow.permute(1,2,0)\n",
    "#     return flow[:,:,0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def pil_norm_flow_image_to_flo(flo_img):\n",
    "#     flo_img = TF.to_tensor(flo_img)\n",
    "#     mean = (0.5, 0.5, 0.5)\n",
    "#     std = (0.5, 0.5, 0.5)\n",
    "#     nor = transforms.Normalize(mean=mean, std=std)\n",
    "#     flow = nor(flo_img)\n",
    "#     flow = flow.permute(1,2,0)\n",
    "#     return flow[:,:,0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def pil_flow_image_to_flo(flo_img):\n",
    "#     flo_img = TF.to_tensor(flo_img)\n",
    "#     mean = (0, 0, 0)\n",
    "#     std = (255, 255, 255)\n",
    "#     nor0_1 = transforms.Normalize(mean=mean, std=std)\n",
    "#     mean = (0.5, 0.5, 0.5)\n",
    "#     std = (0.5, 0.5, 0.5)\n",
    "#     nor = transforms.Normalize(mean=mean, std=std)\n",
    "#     flo_img = nor0_1(flo_img)\n",
    "#     flow = nor(flo_img)\n",
    "#     flow = flow.permute(1,2,0)\n",
    "#     return flow[:,:,0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlowDatasetTransform():\n",
    "    def __init__(self, norm, size=(375, 1242), crop=(320, 896), flip=0.5):\n",
    "        self.norm = norm\n",
    "        self.size = size\n",
    "        self.crop = crop\n",
    "        self.flip = flip\n",
    "\n",
    "        mean = np.array(self.norm.mean)\n",
    "        std = np.array(self.norm.std)\n",
    "\n",
    "        self.inv_norm = transforms.Normalize(mean=-mean/std, std=1/std)\n",
    "\n",
    "    def __call__(self, im_1, im_2, target):\n",
    "        resize = transforms.Resize(size=self.size)\n",
    "        \n",
    "        im_1 = resize(im_1)\n",
    "        im_2 = resize(im_2)\n",
    "#         print(\"target b4 \", target.shape)\n",
    "#         print(\"target b4 \", target[:,:,0])\n",
    "#         print(\"target b4 \", target[:,:,1])\n",
    "        \n",
    "        target = resample_flow(target, self.size)\n",
    "#         print(\"target\", target.shape)\n",
    "#         print(\"target\", target[:,:,0])\n",
    "#         print(\"target\", target[:,:,1])\n",
    "        \n",
    "\n",
    "        i, j, h, w = transforms.RandomCrop.get_params(im_1, output_size=self.crop)\n",
    "#         i, j, h, w = 0, 0, self.crop[0], self.crop[1]\n",
    "\n",
    "        im_1 = TF.crop(im_1, i, j, h, w)\n",
    "        im_2 = TF.crop(im_2, i, j, h, w)\n",
    "        target = target[i:i+h,j:j+w,:]\n",
    "\n",
    "        if False: # random.random() > self.flip:\n",
    "            im_1 = TF.hflip(im_1)\n",
    "            im_2 = TF.hflip(im_2)\n",
    "            target = cv2.flip(target, 1)\n",
    "\n",
    "        target = target.transpose((2, 0, 1))\n",
    "\n",
    "        im_1 = TF.to_tensor(im_1)\n",
    "        im_2 = TF.to_tensor(im_2)\n",
    "        target = torch.Tensor(target)\n",
    "\n",
    "        return norm(im_1), norm(im_2), target\n",
    "\n",
    "    def denorm(self, im):\n",
    "        return self.inv_norm(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlowDatasetTransform_2():\n",
    "    def __init__(self, norm, size=(375, 1242), crop=(320, 896), flip=.5):\n",
    "        self.norm = norm\n",
    "        self.size = size\n",
    "        self.crop = crop\n",
    "        self.flip = .5\n",
    "\n",
    "        mean = np.array(self.norm.mean)\n",
    "        std = np.array(self.norm.std)\n",
    "\n",
    "        self.inv_norm = transforms.Normalize(mean=-mean*std, std=1/std)\n",
    "\n",
    "    def __call__(self, im_1, im_2, target):\n",
    "#         to_PIL = transforms.ToPILImage()\n",
    "        resize = transforms.Resize(size=self.size)\n",
    "     \n",
    "        \n",
    "        norm_Pil = False\n",
    "        \n",
    "        if type(target) is np.ndarray:\n",
    "            if(target.shape[2] is 3): #png\n",
    "                c = TF.to_pil_image(np.uint8(target))\n",
    "            else: #flo\n",
    "                v = torch.from_numpy(target)\n",
    "                v = v.permute(2,0,1)\n",
    "                c = tn_flo_to_PIL_flow_image(v)\n",
    "                norm_Pil = True\n",
    "        \n",
    "        if type(c) is not PIL.Image.Image:\n",
    "            print(\"error\")\n",
    "            raise Exception('target_type not PIL');\n",
    "            \n",
    "            \n",
    "        \n",
    "#         print(im_1)\n",
    "        a = TF.to_pil_image(np.uint8(im_1))\n",
    "        b = TF.to_pil_image(np.uint8(im_2))\n",
    "        \n",
    "        \n",
    "\n",
    "        im_1 = resize(a)\n",
    "        im_2 = resize(b)\n",
    "        target = resize(c)\n",
    "        \n",
    "        \n",
    "#         if type(target) is not PIL.PngImagePlugin.PngImageFile:\n",
    "#             target = TF.to_tensor(target)\n",
    "#             if target.shape[0] == 2:\n",
    "#                 padding = torch.zeros(1, target.shape[1], target.shape[2])\n",
    "#                 target = torch.cat((target, padding), 0)\n",
    "#             target = to_PIL(target)\n",
    "\n",
    "        i, j, h, w = transforms.RandomCrop.get_params(im_1, output_size=self.crop)\n",
    "\n",
    "        im_1 = TF.crop(im_1, i, j, h, w)\n",
    "        im_2 = TF.crop(im_2, i, j, h, w)\n",
    "        target = TF.crop(target, i, j, h, w)\n",
    "        \n",
    "\n",
    "#         if random.random() > self.flip:\n",
    "#             im_1 = TF.hflip(im_1)\n",
    "#             im_2 = TF.hflip(im_2)\n",
    "#             target = TF.hflip(target)\n",
    "\n",
    "        im_1 = TF.to_tensor(im_1)\n",
    "        im_2 = TF.to_tensor(im_2)\n",
    "#         target = TF.to_tensor(target)\n",
    "#         if(norm_Pil is True):\n",
    "        target = pil_norm_flow_image_to_flo(target) #onlu if Pil was not there\n",
    "#         else:\n",
    "#             target = pil_flow_image_to_flo(target)\n",
    "            \n",
    "            \n",
    "            \n",
    "#        if target_type is PIL.Image.Image:\n",
    "#         print(target.shape)\n",
    "\n",
    "        return im_1, im_2, target\n",
    "\n",
    "    def denorm(self, im):\n",
    "        return self.inv_norm(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # set the transform\n",
    "# transform = transforms.Compose([\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.ToPILImage(),\n",
    "#         transforms.Resize((512,512), interpolation=2),\n",
    "#         transforms.ToTensor()\n",
    "#         ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = (.5, .5, .5)\n",
    "std = (.5, .5, .5)\n",
    "norm = transforms.Normalize(mean=mean, std=std)\n",
    "\n",
    "transform = FlowDatasetTransform(norm,size=(384, 512),crop=(384,448))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_loader_kitti = dataset(\"../Data/KittiDataset/training\",\n",
    "#                        transform,\n",
    "#                        input_folder_1 = \"image_2\", \n",
    "#                        input_folder_2 = \"image_2\", \n",
    "#                        gt_folder = \"flow_occ\",\n",
    "#                        input_search_param_1=\"*_10.png\", \n",
    "#                        input_search_param_2 = \"*_11.png\", \n",
    "#                        gt_search_param = \"*_10.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_FlyingChairs = FlowDataset(\"../Data/FlyingChairs_release\",\n",
    "                            tfm_function = transform,\n",
    "                            image_folder=\"data\",\n",
    "                            flow_folder=\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_kitti = torch.utils.data.DataLoader(train_loader_kitti,4,shuffle=True,num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_flyingChairs = torch.utils.data.DataLoader(train_loader_FlyingChairs,batch_size=8,shuffle=True,num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_H5(dataset, path):\n",
    "    index = 0\n",
    "    for inputs1,inputs2,target in dataset:\n",
    "#         print(index)\n",
    "        with h5py.File(path + str(index) + '.h5', 'w') as f:\n",
    "            in1 = f.create_dataset('img1', dtype=np.float32,data=inputs1,compression=\"gzip\", compression_opts=9)\n",
    "            in2 = f.create_dataset('img2', dtype=np.float32,data=inputs2,compression=\"gzip\", compression_opts=9)    \n",
    "#             flo = pil_norm_flow_image_to_flo(target)\n",
    "            targ = f.create_dataset('target', dtype=np.float32,data=target,compression=\"gzip\", compression_opts=9)\n",
    "            index+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_H5(index, path):\n",
    "    with h5py.File(path + str(index) + '.h5', 'r') as f:\n",
    "        img1 = f[\"img1\"][()]\n",
    "        img2 = f[\"img2\"][()]\n",
    "        trg = f[\"target\"][()]\n",
    "        img1_file = torch.from_numpy(img1)\n",
    "        img2_file = torch.from_numpy(img2)\n",
    "        target_file = torch.from_numpy(trg)\n",
    "        return img1_file,img2_file,target_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_batch(im1,im2,target):\n",
    "    for image_1, image_2, target_image in zip(im1,im2,target):\n",
    "        im1_print = image_1.numpy().transpose((1,2,0))\n",
    "        im2_print = image_2.numpy().transpose((1,2,0))\n",
    "        \n",
    "#         print(target_image.shape)\n",
    "\n",
    "#         z = np.zeros((target_image.shape[1],target_image.shape[2]))\n",
    "#         target_print = np.stack((target_image[0],target_image[1], z), axis=0)\n",
    "#         target_print = target_print.transpose((1,2,0))\n",
    "#         print(target_print.shape)\n",
    "#         print(target_image.shape)\n",
    "        print(target_image.shape)\n",
    "#         padding = torch.zeros(target_image.shape[0], target_image.shape[1],1)\n",
    "# #         print(padding.shape)\n",
    "#         target_image = torch.cat((target_image, padding), 2)\n",
    "    \n",
    "        print(torch.max(target_image))\n",
    "        print(torch.min(target_image))\n",
    "        print(target_image.shape)\n",
    "        \n",
    "        target_image = target_image.permute(2,0,1)\n",
    "        target_print=tn_flo_to_PIL_flow_image(target_image)\n",
    "\n",
    "        fig, ax = plt.subplots(1, 3, figsize=(15, 20))\n",
    "        for a in ax:\n",
    "          a.set_axis_off()\n",
    "\n",
    "        ax[0].imshow(im1_print)\n",
    "        ax[1].imshow(im2_print)\n",
    "        ax[2].imshow(target_print)\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write_H5(dataset_kitti, path = '../Data/H5/512by512Kitti/mini_batch_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "write_H5(dataset_flyingChairs, path = '../Data/H5/FlyingChairs_noflip/mini_batch_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 384, 448])\n",
      "tensor(93.7190)\n",
      "tensor(-33.4504)\n",
      "torch.Size([2, 384, 448])\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'tn_flo_to_PIL_flow_image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-d50078d6ca8b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mim1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mim2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_H5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'../Data/H5/FlyingChairs/mini_batch_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mim2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-18-1567323262bb>\u001b[0m in \u001b[0;36mprint_batch\u001b[0;34m(im1, im2, target)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mtarget_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mtarget_print\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtn_flo_to_PIL_flow_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tn_flo_to_PIL_flow_image' is not defined"
     ]
    }
   ],
   "source": [
    "im1,im2,target = read_H5(0,path = '../Data/H5/FlyingChairs_noflip/mini_batch_')\n",
    "print_batch(im1,im2,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read(\"../Data/ChairsSDHom_extended/train/0004142-flow_01.flo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read(\"../Data/ChairsSDHom_extended/train/0007785-img_1.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Path(\"../Data/ChairsSDHom_extended/train/0004142-flow_01.flo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = os.path.basename(root)\n",
    "dir = Path(os.path.dirname(root))\n",
    "s = s.replace('-flow_01.flo', '')\n",
    "im = s + '-img_0.png'\n",
    "ir = s + '-img_1.png'\n",
    "print(dir/im)\n",
    "print(dir/ir)\n",
    "\n",
    "\n",
    "print(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = Image.open('../Data/ChairsSDHom_extended/train/0010306-img_1.png')\n",
    "print(u)\n",
    "type(u)\n",
    "# resize = transforms.Resize((100,100))\n",
    "# resize(u)\n",
    "# u.show()\n",
    "# print(u.width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv2.imread('../Data/ChairsSDHom_extended/train/0004050-img_1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
